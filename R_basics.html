<!DOCTYPE html><html><head><meta charset="utf-8"><style>body {
  width: 45em;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 30px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headeranchor-link {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  display: block;
  padding-right: 6px;
  padding-left: 30px;
  margin-left: -30px;
}

.markdown-body .headeranchor-link:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  position: relative;
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .headeranchor,
.markdown-body h2 .headeranchor,
.markdown-body h3 .headeranchor,
.markdown-body h4 .headeranchor,
.markdown-body h5 .headeranchor,
.markdown-body h6 .headeranchor {
  display: none;
  color: #000;
  vertical-align: middle;
}

.markdown-body h1:hover .headeranchor-link,
.markdown-body h2:hover .headeranchor-link,
.markdown-body h3:hover .headeranchor-link,
.markdown-body h4:hover .headeranchor-link,
.markdown-body h5:hover .headeranchor-link,
.markdown-body h6:hover .headeranchor-link {
  height: 1em;
  padding-left: 8px;
  margin-left: -30px;
  line-height: 1;
  text-decoration: none;
}

.markdown-body h1:hover .headeranchor-link .headeranchor,
.markdown-body h2:hover .headeranchor-link .headeranchor,
.markdown-body h3:hover .headeranchor-link .headeranchor,
.markdown-body h4:hover .headeranchor-link .headeranchor,
.markdown-body h5:hover .headeranchor-link .headeranchor,
.markdown-body h6:hover .headeranchor-link .headeranchor {
  display: inline-block;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* Multimarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px octicons-anchor;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\f05c';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><title>R_basics</title></head><body><article class="markdown-body"><h1 id="overview"><a name="user-content-overview" href="#overview" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Overview</h1>
<h2 id="background"><a name="user-content-background" href="#background" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Background</h2>
<p>Notes on R</p>
<h3 id="working-directory"><a name="user-content-working-directory" href="#working-directory" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Working Directory</h3>
<p>You can set a working directory (e.g. when you try to open up a file, this is the location it looks in)</p>
<pre><code>getwd()  # Gets the current directory
setwd()  # Sets the working directory (your default)
</code></pre>
<h3 id="load-and-save-data"><a name="user-content-load-and-save-data" href="#load-and-save-data" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Load and Save Data</h3>
<p>You can load data using <em>read.csv()</em> and <em>write.csv()</em>.  There&rsquo;s also other varations including <em>write.table()</em></p>
<pre><code>mydata = read.csv(file=&rdquo;C:\\Users\\wliu\\Desktop\\myfile.csv&rdquo;)  # read file
mydata = write.csv(my_dataframe, &ldquo;myfile.csv&rdquo;, sep=&rdquo;,&rdquo;, row.names=FALSE)</code></pre>
<h3 id="help"><a name="user-content-help" href="#help" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Help</h3>
<p>R has built-in help</p>
<pre><code>help(myfunction)
?function
</code></pre>
<h3 id="packages"><a name="user-content-packages" href="#packages" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Packages</h3>
<p>R&rsquo;s capabilities can be expanded with <em>packages</em> from <em>CRAN</em>(Comprehensive R Archive Network)</p>
<pre><code>install.packages(&ldquo;ggplot2&rdquo;, dependencies = TRUE)  # installs package &lsquo;ggplot2&rsquo;
library(ggplot2)  # only need to install once, then can just reference</code></pre>
<p>Some common packages include:<br />
    - foreign  # allows you to load data from SPSS and other formats<br />
    - Rcmdr  # allows data entry, make sure dependencies = TRUE<br />
    - reshape  # allows to change data from wide to long formats<br />
    - ggplot2  # for graphing<br />
    - pastecs  # for basic descriptive statistics of variables; e.g. stat.desc()<br />
    - RODBC  # for conneting to databases (e.g. SQL Server)<br />
    - WRS  # for robust tests<br />
    - Hmisc  # for data analysis (e.g. correlations, computing sample size and power)<br />
    - boot  # for bootstrapping samples<br />
    - car  # for regression diagnostics<br />
    - QuantPsyc  # to get standardized regression coefficients</p>
<h3 id="objects-and-functions"><a name="user-content-objects-and-functions" href="#objects-and-functions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Objects and Functions</h3>
<p>R is made up of <em>objects</em> and <em>functions</em>.  Here&rsquo;s an example of creating an object (my_people) and assigning multiple names using the concatenate function <em>c()</em> (&ldquo;Will&rdquo;, &ldquo;Laura&rdquo;, &ldquo;Mike&rdquo;, &ldquo;Roger&rdquo;)</p>
<pre><code>my_people&lt;-c(&ldquo;Will&rdquo;, &ldquo;Laura&rdquo;, &ldquo;Mike&rdquo;, &ldquo;Roger&rdquo;)  # variable can hold strings
my_age&lt;-c(30, 26, 33, 27)  # variable can hold numbers (no quotes)</code></pre>
<h3 id="dataframes"><a name="user-content-dataframes" href="#dataframes" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>DataFrames</h3>
<p>Dataframes are objects containing variables, like worksheets in Excel.</p>
<pre><code>family&lt;-data.frame(Name=my_people, Age=my_age)  # dataframe w/ 2 variables
family  # display contents of the entire dataframe
#  Name  Age
#1 Will  30
#2 Laura 26
#3 Mike  33
#4 Roger 27
family$Name  # can reference dataframe by variable (e.g. Name)
names()  # can list the variables in the dataframe  # Name, Age
new_family &lt;- family[2,c(&ldquo;Name&rdquo;)]  # rows, columns
# Laura</code></pre>
<h3 id="list-cbind"><a name="user-content-list-cbind" href="#list-cbind" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>list(), cbind()</h3>
<p>The list() and cbind() functions can also be used to combine variables (instead of dataframes)</p>
<pre><code>family&lt;-list(my_people, my_age)  # create two lists
# [1] &ldquo;Will&rdquo; &ldquo;Laura&rdquo; &ldquo;Mike&rdquo; Roger&rdquo;
# [2] 30 26 33 27

family&lt;-cbind(my_people, my_age)  # paste columns of data together
#    my_people, my_age
#[1,] &ldquo;Will&rdquo;, &ldquo;30&rdquo;  # Notice cbind() converts from int to string
#[2,] &ldquo;Laura&rdquo;, &ldquo;26&rdquo;  # cbind() is good only for combining same data types
#[3,] &ldquo;Mike&rdquo;, &ldquo;33&rdquo;
#[4,] &ldquo;Roger&rdquo;, &ldquo;27&rdquo;</code></pre>
<h3 id="useful-functions"><a name="user-content-useful-functions" href="#useful-functions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Useful Functions</h3>
<ul>
<li><strong>rowMeans()</strong> - mean of a row</li>
<li><strong>rowSums()</strong> - sum of a row</li>
<li><strong>sqrt()</strong> - square root</li>
<li><strong>abs()</strong> - absolute value</li>
<li><strong>log10()</strong> - base 10 logarithm</li>
<li><strong>log()</strong> - natural logarithm</li>
<li><strong>is.na()</strong> - is value missing?</li>
<li><strong>ifelse()</strong> - ifelse(a conditional argument, what happens if TRUE, what happens if FALSE)</li>
</ul>
<h3 id="creating-your-own-functions"><a name="user-content-creating-your-own-functions" href="#creating-your-own-functions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Creating your own Functions</h3>
<pre><code>nameOfFunction &lt;- function(input1, input2)
{
    output &lt;- input1 + input2
    cat(&ldquo;Output is: &ldquo;, output)
}</code></pre>
<h3 id="data-formatting-wide-and-longmolten"><a name="user-content-data-formatting-wide-and-longmolten" href="#data-formatting-wide-and-longmolten" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Data Formatting (wide and long/molten)</h3>
<p>The <em>wide format</em> formats data so that each row represents data from one entity while each column represents a variable.  There is no discrimination between independent and dependent variables (each should be its own column)</p>
<pre><code># Wide Format Example
# person, gender, happy_base, happy_6_months, happy_1_year
# Will,  Male, 2, 3, 4
# Laura, Female, 5, 6, 7
</code></pre>
<p>The <em>long or molten format</em> formats data so that scores on different variables (happiness over time) are placed in a single column.</p>
<pre><code># Long or Molten Format Example
# person, gender, variable, value
# Will,  Male, happy_base, 2
# Will,  Male, happy_6_months, 3
# Will,  Male, happy_1_year, 4
# Laura, Female, happy_base, 5
# Laura, Female, happy_6_months, 6
# Laura, Female, happy_1_year, 7
</code></pre>
<p>To reshape the data between <em>wide</em> and <em>long</em> formats, we can use these functions from the <em>reshape</em> package:</p>
<ul>
<li><strong>melt() and cast()</strong></li>
<li><strong>stack() and unstack()</strong></li>
</ul>
<h3 id="filtering-with-by-and-subset"><a name="user-content-filtering-with-by-and-subset" href="#filtering-with-by-and-subset" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Filtering with by() and subset()</h3>
<p>To separate into different groups, we can use <em>by()</em> and <em>subset()</em>.</p>
<ul>
<li><strong>by()</strong> - if you want to split data into different groups, you can use <em>by()</em> with the general form: <code>by(data = dataFrame, INDICES = grouping variable, FUN = a function that you want to apply to the data)</code></li>
<li><strong>subset()</strong> - if you want to split data into different groups, you can use <em>subset()</em> with the general form: <code>subset(data = dataFrame, mycolumn==myvalue</code></li>
</ul>
<h3 id="factor-aka-coding-variable-grouping-variable"><a name="user-content-factor-aka-coding-variable-grouping-variable" href="#factor-aka-coding-variable-grouping-variable" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Factor (aka coding variable, grouping variable)</h3>
<p>Factors are variables that take on a limited number of different values (i.e. <em>categorical variables</em>) and is helpful in statistical modeling.  Use the functions <em>factor()</em> (says this data is a categorical) and <em>levels()</em> (shows the different categories).</p>
<pre><code>data = c(1,2,2,3,1,2,3,3,1,2,3,3,1)
fdata = factor(data, levels=c(a,b,c), labels=(&ldquo;x&rdquo;,&rdquo;y&rdquo;,&rdquo;z&rdquo;)) # Levels: 1 2 3

my_months = c(&ldquo;January&rdquo;,&rdquo;February&rdquo;,&rdquo;March&rdquo;,
          &ldquo;April&rdquo;,&rdquo;May&rdquo;,&rdquo;June&rdquo;,&rdquo;July&rdquo;,&rdquo;August&rdquo;,&rdquo;September&rdquo;,
          &ldquo;October&rdquo;,&rdquo;November&rdquo;,&rdquo;December&rdquo;)
ordered_months = factor(my_months,levels=c(&ldquo;January&rdquo;,&rdquo;February&rdquo;,&rdquo;March&rdquo;,
                        &ldquo;April&rdquo;,&rdquo;May&rdquo;,&rdquo;June&rdquo;,&rdquo;July&rdquo;,&rdquo;August&rdquo;,&rdquo;September&rdquo;,
                        &ldquo;October&rdquo;,&rdquo;November&rdquo;,&rdquo;December&rdquo;),ordered=TRUE)
ordered_months  # Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; July &lt; August &lt; September &lt; October &lt; November &lt; December</code></pre>
<h3 id="plotting-graphs-with-ggplot2"><a name="user-content-plotting-graphs-with-ggplot2" href="#plotting-graphs-with-ggplot2" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Plotting Graphs with ggplot2</h3>
<p>You can do a quick plot using <em>qplot()</em> (quick and easy) or build a plot layer by layer using <em>ggplot()</em> (for more detailed plots).  Plots are made up of <code>ggplot(myData, aes(variable for x, variable for y)) + geoms() + opts() + theme()</code>.  For full documentation, see: <a href="http://docs.ggplot2.org/">http://docs.ggplot2.org/</a></p>
<ul>
<li>
<p><strong>aes</strong> - aesthetic properties, what the <em>geoms</em> look like (e.g. size, color, shape) and where they&rsquo;re plotted.  Examples include:</p>
<ul>
<li><strong>colour()</strong> - specify exact colors using RRGGBB system (e.g. #3366FF) for a shade of blue</li>
<li><strong>alpha()</strong> - specify transparency from 0 (for fully transparent) to 1 (fully opaque)</li>
<li><strong>linetype()</strong> - specify if line is solid (1), hashed (2), dotted(3), dot and dash (4), long hash (5), dot and long hash (6)</li>
<li><strong>size()</strong> - specify size in mm (default is 0.5); larger for larger, smaller for smaller</li>
<li><strong>shape()</strong> - an int between 0 and 25, each specifying a type of shape, e.g. hollow square (0), hollow triangle (1), + sign (2)</li>
</ul>
</li>
<li>
<p><strong>geoms</strong> - geometric objects, these are the visual elements of an object (e.g. bars, data points, text).  Each layer of the _geoms__ can accept additional arguments to change that layer&rsquo;s <strong>aes</strong> (aesthetics).  Some common geoms include:</p>
<ul>
<li><strong>geom_bar()</strong> - creates a layer with bars representing statistical properties</li>
<li><strong>geom_point()</strong> - creates a layer showing the data points (e.g. scatterplot)</li>
<li><strong>geom_line()</strong> - creates a layer that connects data points with a straight line</li>
<li><strong>geom_smooth()</strong> - creates a layer that contains a smoother line</li>
<li><strong>geom_histogram()</strong> - creates a layer with a histogram</li>
<li><em>Note</em>: ggplot has some built-in <em>stats</em> functions (e.g. <em>bin</em> to bin data, <em>boxplot</em> to compute the data for a boxplot, <em>summary</em> to summarize data) that it uses behind the scenes.  You can adjust these properties manually if you&rsquo;d like.  For a full list, look under &lsquo;Statistics&rsquo; in the documentation.</li>
</ul>
</li>
<li>
<p><strong>position</strong> - this is just an argument, but a useful one.  You can make position adjustments on any object (e.g. <em>geom</em> or <em>aes</em>) in a plot with the <code>position = "x"</code> where x can be:</p>
<ul>
<li><strong>dodge</strong> - no overlap at the side</li>
<li><strong>stackfill</strong> - makes objects stack on top of each other (largest objects on bottom, smallest on top) </li>
<li><strong>fill</strong> - standardizes everything to an equal height (1) and makes objects stack on top of each other to fill the bar</li>
<li><strong>identity</strong> - no position adjustment</li>
<li><strong>jitter</strong> - jitter points to avoid overplotting on top of each other</li>
</ul>
</li>
<li>
<p><strong>facet_grid() and facet_wrap()</strong> - faceting splits plots into subgroups.  </p>
<ul>
<li><strong>facet_grid()</strong> - <em>facet grid</em> splits the data by the combination of  variables (e.g. Male Introverts, Female Introverts, Male Extroverts, Female Extroverts).  The general format is <code>+ facet_grid(x ~ y)</code> where <em>x</em> and <em>y</em> are the variables you want to facet</li>
<li><strong>facet_wrap()</strong> - <em>facet wrap</em> splits the data by a single variable (e.g. Satisfied, Neutral, Not Satisfied). The general format is <code>+ facet_wrap( ~ y, nrow = integer, ncol = integer)</code> where <em>nrow</em> and <em>ncol</em> are optional</li>
</ul>
</li>
<li>
<p><strong>stat_summary()</strong> - summarizes y values at every unique x.  The general form is: <code>stat_summary(function = x, geom = y)</code></p>
<ul>
<li><strong>fun.y = mean</strong> - the mean; usually used with <em>geom = &ldquo;bar&rdquo;</em></li>
<li><strong>fun.y = median</strong> - the median; usually used with <em>geom = &ldquo;bar&rdquo;</em></li>
<li><strong>fun.data = mean_cl_normal()</strong> - 95% confidence intervals assuming normality; usually used with <em>geom = &ldquo;errorbar&rdquo;</em> or <em>geom = &ldquo;pointrange&rdquo;</em></li>
<li><strong>fun.data = median_hilow()</strong> - median and upper and lower quantiles; usually used with <em>geom = &ldquo;pointrange&rdquo;</em></li>
</ul>
</li>
<li>
<p><strong>ggsave()</strong> - lets you save the graph; E.g. <code>ggsave("mygraph.png", width = 2, height = 2)</code></p>
</li>
<li>
<p><strong>theme() and opts()</strong> - <em>theme()</em> allows you to control the themes of how plots look, default is theme_grey().  <em>opts()</em> allows you to controls pecific parts of the theme (e.g. just the axis.line)</p>
<ul>
<li><strong>theme_text()</strong> - font, colour, size of labels</li>
<li><strong>theme_line()</strong> - colour, size, linetype for grid lines</li>
<li><strong>theme_segment()</strong> - colour, size, linetype for axis line and axis tick marks</li>
</ul>
</li>
</ul>
<h3 id="parametric-statistics"><a name="user-content-parametric-statistics" href="#parametric-statistics" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Parametric Statistics</h3>
<p>A branch of statistics that assumes the data comes from a type of probability distribution and makes inferences about the parameters of the distribution.  The assumptions are:</p>
<ul>
<li><strong>normal distribution</strong> - different depending on the test you&rsquo;re using (remember sample size affects how we test for <em>normal distribution</em>).  What we want is a skew = 0 and kurtosis = 0.  We can eye-ball this with &lsquo;stat_function()&rsquo; and &lsquo;Q-Q plot&rsquo;; we can also quantify it with numbers using <ul>
<li><strong>stat_function()</strong> - draws a function over the current plot layer; for example, using the argument <em>fun = dnorm()</em>, which returns the probability (i.e. the density) for a given value</li>
<li><strong>Q-Q plot (quantile-quantile plot)</strong> - a <em>quantile</em> is the proportion of cases we find below a certain value; using the <code>stat = "qq"</code> argument in a <em>qplot()</em>, we can plot the cumulative values we have in our data against the cumulative probability of a normal distribution (i.e. data is ranked and sorted).  If data is normally distributed, then the actuals scores will have the same distribution as the score so we&rsquo;ll get a straight diagonal line <br />
To get more accurate (instead of just eye-balling), we can:</li>
<li><strong>describe() or stat.desc()</strong> - We can get descriptive summaries of our data with the <em>describe()</em> function of the &lsquo;psych&rsquo; package or <em>stat.desc()</em> function of the &lsquo;pasetcs&rsquo; package.  Again, we&rsquo;re interested in <code>skew = 0</code> and <code>kurtosis = 0</code>, which we can then calculate the <em>z-score</em> (so that we can compare to different samples that used different measures and so that we can see how likely our values of <em>skew</em> and <em>kurtosis</em> are likely to occur).</li>
<li><strong>z-score skewness calculation</strong> - the z-score for skewness can be calculated using <code>insert formula for z-score skewness</code></li>
<li><strong>z-score kurtosis calculation</strong> - the z-score for kurtosis can be calculated using <code>insert formula for z-score kurtosis</code></li>
<li><em>Note:</em> interpretting z-scores depends on the sample size.  Absolute value greater than 1.96 is significant at &lsquo;p &lt; .05&rsquo;, greater than 2.58 at &lsquo;p &lt; .01&rsquo;, greater than 3.29 is significant at &lsquo;p &lt; .001&rsquo;<ul>
<li><em>small samples (&lt;30)</em> - it&rsquo;s okay to look for values above 1.96</li>
<li><em>large samples(&gt;30 and &lt;200)</em> - it&rsquo;s okay to look for values above 2.58</li>
<li><em>very large samples (_200+)</em> - look at the shape&rsquo;s distribution visually and value of the skew and kurtosis statistics instead of calculating their significance (because they are likely to be significant even when skew and kurtosis are not too different than normal)</li>
</ul>
</li>
<li><strong>skew.2SE and kurt.2SE</strong> - <em>stat.desc()</em> gives us <em>skew.2SE.</em> and <em>kurt.2SE</em>, which stands for the <em>skew</em> and <em>kurtosis</em> value divided by 2 standard errors (i.e. instead of values above, we can say if the absolute value greater than 1 is significant at &lsquo;p &lt; 0.5&rsquo;, greater than 1.29 at &lsquo;p &lt; .01&rsquo;, greater than 1.65 is significant at &lsquo;p &lt; .001&rsquo;)</li>
<li><strong>Shapiro-Wilk Test of Normality</strong> - <em>Shapiro-Wilk</em> is a way of looking for normal distribution by checking whether the distribution as a whole deviates from a comparable normal distribution.  This is represented as <em>normtest.W</em> (W) and <em>normtest.p</em> (p-value) through either the <em>stat.desc()</em> or <em>shapiro.test()</em> functions</li>
</ul>
</li>
<li><strong>homogeneity of variance</strong> - variances should be the same throughout the data (i.e. data is tightly packed around the mean).  For example, say we measured the number of hours a person&rsquo;s ear rang after a concert across multiple concerts.<ul>
<li><strong>homogeneity of variance</strong> - After each concert, the ringing lasts about 5 hours (even if this is sometimes 10-15 hours, 20-25 hours, 40-45 hours)</li>
<li><strong>heterogeneity of variance</strong> - After each concert, the ringing lasts from 5 to 30 hours (say first concert is 5-10 hours, last concert is 20-50 hours)</li>
<li><strong>Levene&rsquo;s test (F)</strong> - <em>Levene&rsquo;s test</em> tests that the variances in different groups are equal (i.e. the difference between variances is equal to zero).<ul>
<li>Test is significant at p &lt;= .05, which we can then conclue that the variances are significantly different (meaning it is not <em>homogeneity of variance</em>)</li>
<li>Test is non-significant at p &gt; .05, then the variances are roughly equal and it is <em>homogeneity of variance</em></li>
<li>In <em>R</em>, we can use the <em>leveneTest()</em> function from the <em>car</em> package.  It looks like this general form: <code>leveneTest(outcome variable, grouping variable, center = median/mean)</code> where the outcome variable is what we want to test the variances and the grouping variable is a factor</li>
<li><em>Note:</em> in large samples, Leven&rsquo;s test can be significant even when group variances are not very different; for this reason, it should be interpreted with the <em>variance ratio</em></li>
</ul>
</li>
<li><strong>Hartley&rsquo;s Fmax (aka variance ratio)</strong> - the ratio of the variances between the group with the biggest variance the group with the smallest variance.  This value should be smaller than the critical values</li>
</ul>
</li>
<li><strong>interval data</strong> - data should be measured at least in the interval level (tested with common sense)</li>
<li><strong>independence</strong> - different depending on the test you&rsquo;re using</li>
</ul>
<h3 id="linear-regression-data-cleaning-trying-to-make-data-fit-into-a-normal-distribution-and-what-happens-when-you-cant"><a name="user-content-linear-regression-data-cleaning-trying-to-make-data-fit-into-a-normal-distribution-and-what-happens-when-you-cant" href="#linear-regression-data-cleaning-trying-to-make-data-fit-into-a-normal-distribution-and-what-happens-when-you-cant" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Linear Regression - Data Cleaning (trying to make data fit into a normal distribution, and what happens when you can&rsquo;t)</h3>
<p>After checking that the data was entered in correctly, you can do the following:</p>
<ul>
<li><strong>Remove the outlier</strong> - delete the case only if you believe this is not representative (e.g. for Age someone puts 200, pregnant male)</li>
<li><strong>Data transformation</strong> - do trial and error data transformations.  If you&rsquo;re looking at differences between variables you must apply the same transformation to all variables.  Types of transformations include:<ul>
<li><strong>Log transformation log(Xi)</strong> - taking the logarithm of a set of numbers squashes the right tail of the distribution.  Advantages is this corrects for <em>positive skew</em> and <em>unequal variances</em>.  Disadvantage is that you can&rsquo;t take the log of zero or negative numbers (though you can do log(x +1) to make it positive where 1 is the smallest number to make the value positive.</li>
<li><strong>Square root transformation</strong> - Taking the square root centers your data (square root affects larger values more than smaller values).  Advantage is it corrects <em>positive skew</em> and <em>unequal variances</em>.  Disadvantage is same as log, no square root of negative numbers</li>
<li><strong>Reciprocal transformation (1/Xi)</strong> - divide 1 by each score reduces the impact of large scores.  This reverses the score (e.g. a low score of 1 would create 1/1 = 1; a high score of 10 would create 1/10 = 0.1).  The small score becomes the bigger score.  You can avoid score reversal by reversing the scores before the transformation 1/(X highest - Xi).Advantages is this corrects <em>positive skew</em> and <em>unequal variances</em></li>
<li><strong>Reverse Score transformation</strong> - The above transformations can correct for <em>negative skew</em> by reversing the scores.  To do this, subtract each score from the highest score obtained or the highest score + 1 (depending if you want lowest score to be 0 or 1).  Big scores have become small and small scores have become big.  Make sure to reverse this or interpret the variable as reversed. </li>
</ul>
</li>
<li><strong>Change the score</strong> - if transformation fails, consider replacing the score (it&rsquo;s basically the lesser of two evils) with one of the following:<ul>
<li>Change the score to be one unit above the next highest score in the data set</li>
<li>The mean plus three standard deviations (i.e. this converts back from a z-score)</li>
<li>The mean plus two standard deviations (instead of three times above)</li>
</ul>
</li>
<li>
<p><strong>Dummy coding</strong> - is a way of representing groups of people using only zeros and ones.  To do this, we create several variables (one less than the number of groups we&rsquo;re recoding) by doing:</p>
<ul>
<li>Count the number of groups you want to recode and subtract 1</li>
<li>Create as many new (dummy) variables as step above</li>
<li>Choose one of your groups as a baseline; this should be your control group or the group that represents the majority of your people (because it might be interesting to compare other groups against the majority)</li>
<li>Assign the baseline group value of 0 for all of your dummy variables</li>
<li>For the first dummy variable, assign value of 1 to the first group that you want to compare against the baseline and 0 for all other groups</li>
<li>Repeat above step for all dummy variables</li>
<li>Place all your dummy variables into analysis</li>
</ul>
</li>
<li>
<p><strong>Robust test (robust statistics)</strong> - statistics that are not unduly affected by outliers or other small departures from model assumptions (i.e. if the distribution is not normal, then consider using a <em>robust test</em> instead of a <em>data tranformation</em>).  These tests work using these two concepts <em>trimmed mean</em> and <em>bootstrap</em>:</p>
<ul>
<li><strong>trimmed mean</strong> - a mean based on the distribution of scores after you decide that some percentage of scores will be removed from each extreme (i.e. remove say 5%, 10%, or 20% of top and bottom scores before the mean is calculated)<ul>
<li><strong>M-estimator</strong> - slightly different than <em>trimmed mean</em> in that the <em>M-estimator</em> determines the amount of trimming empiraccly.  Advantage is that we never over or under trim the data.  Disadvantage is sometimes <em>M-estimators</em> don&rsquo;t give an answer.</li>
</ul>
</li>
<li><strong>bootstrap</strong> - <em>bootstrap</em> estimates the properties of the sampling distribution from the sample data.  It treats the sample data as a population from which smaller samples (<em>bootstrap samples</em>) are taken with replacement (i.e. puts the data back before a new sample is taken again).</li>
<li><em>Note:</em> <em>R</em> has a package called <em>WRS</em> that has these <em>robust tests</em>, including <em>boot()</em><ul>
<li><code>my_object &lt;- boot(data, function, replications)</code> where <em>data</em> is the dataframe, <em>function</em> is what you want to bootstrap, <em>replications</em> is the number of bootstrap samples (usually 2,000)</li>
<li><em>boot.ci(my_object)</em> returns an estimate of bias, empirically derived standard error, and confidence intervals</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="linear-regression-covariance-and-correlation"><a name="user-content-linear-regression-covariance-and-correlation" href="#linear-regression-covariance-and-correlation" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Linear Regression - Covariance and Correlation</h3>
<p>We can see the relationship between variables with <em>covariance</em> and the <em>correlation coefficient</em>.</p>
<ul>
<li><strong>variance</strong> - remember that <em>variance</em> of a single variable represents the average amount that the data vary from the mean</li>
<li><strong>covariance</strong> - <em>covariance</em> is a measure of how one variable changes in relation to another variable.  Positive covariance means if one variable moves in a certain direction (e.g. increases), the other variable also moves in the same direction (e.g. increases).  Negative covariance means if one variable moves in a certain direction (e.g. increases), the other variable moves in the opposite direction (e.g. decreases).<ul>
<li><strong>deviance</strong> - remember that <em>deviance</em> is the difference in value vertically (i.e. the quality of fit)</li>
<li><strong>cross-product deviations</strong> - when we multiple the <em>deviation</em> of one variable by the corresponding <em>deviation</em> of another variable</li>
<li><strong>covariance</strong> - the average sum of combined deviations (i.e. it&rsquo;s the cross-product deviation, but also divided by the number of observations, N-1)</li>
<li><em>Note:</em> <em>covariance</em> is NOT a good standardized measure of the relationship between two variables because it depends on the scales of measurement (i.e. we can&rsquo;t say whether a covariance is particularly large relative to another data set unless both data sets used the same units).</li>
<li><strong>standardization</strong> - is the process of being able to compare one study to another using the same unit of measurement (e.g. we can&rsquo;t compare attitude in metres)</li>
<li><strong>standard deviation</strong> - the unit of measurement that we use for <em>standardization</em>; it is a measure of the average <em>deviation</em> from the mean</li>
</ul>
</li>
<li><strong>correlation coefficient</strong> - this is the standardized covariance; we basically get the standard deviation of the first variable, multiply by the standard deviation of the second variable, and divide by the product of the multiplication.  There&rsquo;s two types of correlations including <em>bivariate</em> and <em>partial</em>:<ul>
<li><strong>bivariate correlation</strong> - correlation between two variables.  Can be:<ul>
<li><strong>Pearson product-moment correlation (aka Pearson correlation coefficient)</strong> - for parametric data that requires interval data for both variables</li>
<li><strong>Spearman&rsquo;s rho</strong> - for non-parametric data (so can be used when data is non-normally distributed data) and requires only ordinal data for both variables.  This works by first ranking the data, then applying <em>Pearson&rsquo;s equestion</em> to the ranks.</li>
<li><strong>Kendall&rsquo;s tau</strong> - for non-parametric data, similar to Spearman&rsquo;s, but use this when there&rsquo;s a small number of samples and there&rsquo;s a lot of tied ranks (e.g. lots of &lsquo;liked&rsquo; in ordinal ranks of: dislike, neutral, like)</li>
</ul>
</li>
<li><strong>partial correlation</strong> - correlation between two variables while &lsquo;controlling&rsquo; the effect of one or more additional variables</li>
<li><em>Note:</em> values range from -1 (negatively correlated) to +1 (positively correlated)<ul>
<li>+1 means the two variables are perfectly positively correlated (as one increases, the other increases by a proportional amount)</li>
<li>0 means no linear relationship (if one variable changes, the other stays the same)</li>
<li>-1 means the two variables are perfectly negatively correlated (as one increases, the other decreases in a proportional amount)</li>
<li><strong>correlation matrix</strong> - if you want to get correlation coefficients for more than two variables (a gird of correlation coefficients)</li>
<li><strong>correlation test</strong> - if you only want a single correlation coefficient</li>
</ul>
</li>
<li><em>R</em> to calculate correlation, we can the <em>Hmisc</em> package, specifically with <em>cor()</em>, <em>cor.test()</em>, and <em>rcorr()</em></li>
<li><strong>causaulity</strong> - <em>correlation</em> does not give the direction of causality (i.e. correlation does not imply causation)</li>
<li><strong>third-variable problem (aka tertium quid)</strong> - <em>causality</em> between two variables cannot be assumed because there may be other measured or unmeasured variables affecting the results</li>
</ul>
</li>
<li><strong>coefficient of determination (R^2)</strong> - a measure of the amount of variability in one variable that is shared by the other (i.e. indicates how well data fit a statistical model); this is simply the <em>correlation coefficient</em> squared.  If we multiply this value by 100, we can say that variable A CAN (not necessarily does) account up to X% of variable B.  R</li>
<li><strong>biserial and point-biserial correlation coefficient</strong> - these correlational coefficients are used when one of the two variables is <em>dichotomous (aka binary)</em>.  <em>point-biserial correlation</em> is used when one variable is a <em>discrete</em> dichotomy (i.e. dead or alive, can&rsquo;t be half-dead).  <em>biserial correlation</em> is used when that one variable is a <em>continuous</em> dichotomy (i.e. your grade is pass or fail, but it can have multiple levels including A+, C-, F).</li>
<li><strong>partial correlation and semi-partial correlation (aka part correlation)</strong> - a <em>partial correlation</em> is the relationship between two variables while controlling for the effects of a third variable on both variables in the original correlation.  <em>semi-partial correlation</em> is the relationship between two variables while controlling for the effects of a third variable on only one of the variables in the original correlation.</li>
</ul>
<h3 id="linear-regression-analysis"><a name="user-content-linear-regression-analysis" href="#linear-regression-analysis" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Linear Regression Analysis</h3>
<p><em>Regression Analysis</em> is a way of predicting an outcome variable from one predictor variable (<em>simple regression</em>) or from several predictor variables (<em>multiple regression</em>).  We fit a model to our data and use it to predict values of the <em>dependent variable</em> from one or more <em>independent variables</em>.  *  <strong>method of least squares_ - method to find the line of best fit, which finds the smallest <em>residuals</em> (aka the difference, variance) between the actual data and our model<br />
<em>  <strong>regression model (aka regression line)</strong> is the line of best fit resulting from the <em>method of least squares</em>.  Remember that even though this is the best fitting line, the model could still be a bad fit to the data</em>  __residual sum of squares (aka sum of squared residuals)</strong> - represents the degree of inaccuracy when the best model is fitted to the data<br />
<em>  <strong>model sum of squares</strong> - the improvement going from the worst fit line (which just uses the mean for every value) to the best fit line (our <em>regression model</em>).  If this value is large, then the <em>regression model</em> has made a big improvement on how well the outcome variable can be predicted.  If this value is small, then the model isn&rsquo;t much of an improvement.</em>  <strong>F-statistic (aka F-ratio, F-test)</strong> - a test statistic determines the systematic variance divided by the unsystematic variance (i.e. a measure of how much the model has improved the prediction of the outcome compared to the level of inaccuracy of the model).  A large value (greater than at least 1) means a good model.  The <em>F-test</em> is based on the ratio of the improvement due to the <em>model sum of squares</em> and the difference between the model and the observed data <em>residual sum of squares</em>.<br />
<em>  <strong>t-statistic</strong> - like the <em>F-test</em>, usually used in <em>t-tests</em>, helps us assess predictor variables in whether they improve our model</em>  <strong>ANOVA (analysis of variance)</strong> - tells us whether the overall model results in a good degree of prediction of the outcome variable (Note: it doesn&rsquo;t tell us about the individual contribution of variables in the model)<br />
<em>  <strong>Akaike information criterion (aka AIC)</strong> - measure of fit (like R^2), except that it penalizes the model for having more variables (whereas R^2 only fits the data better with more predictors).  <code>insert formula</code>.  The bigger the value means a worse fit, smaller the value means better fit.  Only compare the AIC to models of the same data (there&rsquo;s no reference; can&rsquo;t say 10 is small or big).</em>  <strong>Bayesian information criterion (aka BIC)</strong>, a measure of fit like <em>AIC</em>, but has a larger penalty for more variables than <em>AIC</em>.  <code>insert formula</code>.  </p>
<h3 id="linear-regression-selecting-predictors"><a name="user-content-linear-regression-selecting-predictors" href="#linear-regression-selecting-predictors" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Linear Regression - Selecting Predictors</h3>
<p>If you&rsquo;re making a complex model, the selection of predictors and its order can have a huge impact.  Put predictors methodically, not just add a bunch and see what results happen.  Here&rsquo;s a few methods:<br />
<em>  <strong>Hierarchical Regression</strong> is where predictors are selected based on past work and the experimenter decides what order to enter the predictors into the model.  Known predictors should be entered in first in order of importance in predicting the outcome.</em>  <strong>Forced entry</strong> is where all predictors are carefully chosen, then forced into the model simultaneously in random order.<br />
*  <strong>Stepwise methods</strong> is where all predictors and their order are based off a mathematical criterion and has a direction of <em>forward, backward, both</em>.<br />
    -  <strong>Forward Direction (aka Forward Selection)</strong> - An initial model is defined that contains only the constant, then the computer searches for the predictor (out of the ones available) that best predicts the outcome variable.  If the model improves the ability to predict the outcome, the predictor is retained.  The next predictor selected is based on the largest semi-partial correlation (i.e. the &lsquo;new variance&rsquo;; if predictor A explains 40% of the variation in the outcome variable, then there&rsquo;s 60% variation left unexplained.  If predictor B is measured only on the remaining 60% variation).  We stop selecting predictors when the <em>AIC</em> goes up on the remaining variables (remember lower <em>AIC</em> means better model)<br />
    -  <strong>Backward Direction (aka Backward Elimination)</strong> - An initial model that starts with all predictor variables, removes one at a time, stops if remaining variables makes <em>AIC</em> go up (remember lower <em>AIC</em> means better model).  This is the preferred method because of <em>suppressor effects</em>, which occurs when a predictor has an effect but only when another variable is held constant.  <em>Forward Direction</em> is more likely than <em>Backward Direction</em> to exclude predictors involved in suppressor effects (and thus make a <em>Type II error</em>)<br />
    -  <strong>Both Direction (aka stepwise)</strong> - Starts the same as <em>Forward Direction</em>, but whenever you add a predictor, a removal test of the least useful predictor is done to see if there&rsquo;s any redundant predictors<br />
    - <strong>Note:</strong> If you used one of the above stepwise methods to get dressed on a cold day, you might put on pants first instead of underwear.  It&rsquo;ll see that underwear doesn&rsquo;t fit now that you have pants on so it&rsquo;ll skip.  If you don&rsquo;t mind your computer doing lots of calculations, try the <em>all-subsets</em> method.<br />
    -  <strong>All-subsets methods</strong> is where we try every combination of predictors to see which is the best fit (using a statistic called <em>Mallow&rsquo;s Cp</em>).  You can increase accuraccy, but the possibilities increase exponentially so calculations take much longer.<br />
    -  <strong>Another Note:</strong> There&rsquo;s a huge danger of over-fitting with too many variables so it&rsquo;s important to <strong>cross-validate</strong> the model by splitting into train/test sets.  Remember, the fewer predictors the better.</p>
<h3 id="linear-regression-hows-my-model-doing"><a name="user-content-linear-regression-hows-my-model-doing" href="#linear-regression-hows-my-model-doing" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Linear Regression - How&rsquo;s my model doing?</h3>
<p>When making a model, we should check for two things 1.) how well the model fits the observed data through <em>outliers, residuals, influence cases</em> and 2.) for <em>generalization</em>, which is how the model generalizes to other cases outside your sample).<br />
<em>  <strong>Outliers and Residuals</strong> - We want to look at outliers to see if a small number of cases heavily influence the entire model.  What we do is look for <em>residuals</em>, which is the error pressent in the model (smaller the value, the better the fit.  Large values mean outliers).<br />
    - <strong>Unstandardized residuals (normal residuals)</strong> are measured in the same units as the outcome variable and are difficult to interpret across different models.  We cannot define a universal cut-off point of what is an <em>outlier</em>.  Instead, we need <em>standardized residuals</em>.<br />
    - <strong>Standardized residuals</strong> are <em>residuals</em> divided by an estimate of their <em>standard deviation</em>, which gives us the ability to compare residuals from different models using the properties of <em>z-scores</em> to determine universal guidelines on acceptable and unacceptable values.  E.g. Normally distributed sample, 99% of z-scores should lie between -3.29 and 3.29.  Anything above or below these values are cause for concern and thus the model is a bad fit.</em>  <strong>Influential Cases</strong> - We should also check to see that any influential cases aren&rsquo;t greatly biasing the model.  We can assess the influence of a particular case using multiple methods:<br />
    -  <strong>Adjusted Predicted Value</strong> - So basically, two models are created; one without a particular case and with the case.  The models are then compared to see if the predicted value is the same regardless of whether the value is included.  If the predicted value is the same, the model is good.  If the predicted value is not the same, the model is a bad fit.  The <em>adjusted predicted value</em> is the predicted value for the model without the case.<br />
        + <strong>DFFit</strong> is the difference between the <em>adjusted predicted value</em> (when the model doesn&rsquo;t include a case) from the original predicted value (when the model includes the case).<br />
        + <strong>DFBeta</strong> is the difference between a parameter estimated using all cases and estimated when one case is excluded<br />
    -  <strong>Studentized Residual</strong> is when the residual is divded by the standard error so it gives us a standardized value; this can be compared across different regression analyses because it is measured in standard units.  It&rsquo;s called the studentized residual because it follows a <em>Student&rsquo;s t-distribution</em>.  This is useful to assess the influence of a case on the ability of the model to predict the case, but doesn&rsquo;t provide info on how a case influences the model as a whole (i.e. the ability to predict all cases)<br />
    -  <strong>Cook&rsquo;s distance</strong> is a statistic that considers the effect of a single case on the model as a whole (i.e. the overall influence of a case on the model); any values greater than 1 may be cause for concern<br />
    -  <strong>hat values (aka leverage)</strong> is another way to check the influence of the observed value of the outcome variable over the predicted values (0 means the case has no influence up to 1 meaning the case has complete influence).  The formula is <code>insert formula</code>.  If no cases exert undue influence over the model, then all leverage values should be close to the average value.  Some recommend investigating cases greater than twice to three times the average.</p>
<h3 id="assumptions-in-linear-regression-analysis"><a name="user-content-assumptions-in-linear-regression-analysis" href="#assumptions-in-linear-regression-analysis" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Assumptions in Linear Regression Analysis</h3>
<ul>
<li><strong>Generalization</strong> asks the question of whether our model can generalize to other cases outside of this sample (i.e. apply to a wider population)?  We need to check for these assumptions in regression analysis.  Once these below assumptions are met, the coefficients and parameters of the regression equation are said to be <em>unbiased</em>.  An <em>unbiased model</em> tells us that on average, the regression model from the sample is the same as the population model (but not 100%)<ul>
<li><strong>Variable types</strong> - All predictor variables must be quantitative or categorical (with two categories).  The outcome variable must be quantitative (measured at the interval level), continuous, and unbounded (no constraints on the variability of the outcome; e.g. if the outcome is a measure ranging from 1 to 10 yet the data collected vary between 3 and 7, then its constrained)</li>
<li><strong>Non-zero variance</strong>  - Predictors should have some variation in value (i.e. do not have variances of 0)</li>
<li><strong>No perfect multicollinearity</strong> - Should be no perfect linear relationship between two or more predictors (and don&rsquo;t correlate too highly).</li>
<li><strong>Predictors are uncorrelated with &lsquo;external variables&rsquo;</strong> - external variables that haven&rsquo;t been included in the regression model which influence the outcome variable.  If external variables do correlate with the predictors, then the conclusions we draw from the model are unreliable (because other variables exist that can predict the outcome)</li>
<li><strong>Homoscedasticity</strong> - At each level of the predictor variable(s), the variance of the residual terms should be constant.  The residuals at each level of the predictor(s) should have the same variance (<em>homoscedasticity</em>); when the variances are very unequal there is <em>heteroscedasticity</em></li>
<li><strong>Independent Errors</strong> - For any two observations the residual terms should be uncorrelated (i.e. independent, sometimes called lack of <em>autocorrelation</em>).<ul>
<li><strong>Durbin-Watson test</strong> is a test that checks for serial correlations between errors (i.e. whether adjacent residuals are correlated).  The test statistic can vary between 0 and 4:<ul>
<li>2 means that the residuals are uncorrelated</li>
<li>&lt;2 means a positive correlation between adjacent residuals</li>
<li>
<blockquote>
<p>2 means a negative correlation between adjacent residuals</p>
</blockquote>
</li>
<li>&lt;1 or &gt;3 means definite cause for concern</li>
<li>Even if value is close to 2, can still be cause for concern (this is just a quick test, still depends on sample size and model)</li>
<li><em>Note:</em> this test depends on the order; if you reorder the data, you&rsquo;ll get a different value</li>
</ul>
</li>
</ul>
</li>
<li><strong>Normally Distributed Errors</strong> - assumed that the residuals in the model are random, normally distributed variables with a mean of 0, which means the differences between the model and the observed data are most frequently zero or close to zero and that differences greater than zero are rare.  <em>Note:</em> does not mean that predictors have to be normally distributed</li>
<li><strong>Independence</strong> - All the values of the outcome variable are independent</li>
<li><strong>Linearity</strong> - the mean values of the outcome variable for each increment of the predictor(s) lie along a straight line (i.e. this is a regression, we should be modeling a linear relationship)</li>
</ul>
</li>
<li><strong>Cross-validation</strong> - A way to assess the accuracy of our model/ how well our model can predict the outcome in a different sample.  If a model is generalized, it can predict another sample well.  If the model is not generalized, it can&rsquo;t predict another sample well. <ul>
<li><em>Adjusted R^2</em> - this adjusted value indicates the loss of predictive power (aka <em>shrinkage</em>).  The equation is <em>Stein&rsquo;s Formula</em>, <code>insert formula</code>.  Note this is different than R^2, which uses <em>Wherry&rsquo;s equation</em>.</li>
<li><em>Data splitting</em> - Usually split data randomly to 80% train, 20% test</li>
<li><em>Sample size</em> - Depends on the size of effect (i.e. how well our predictors predict the outcome), how much statistical power we want and the number of predictors.  As a general rough guide, check out Figure 7.10 in the book (Page 275)</li>
<li><em>Multicollinearity</em> - exists when there is a strong relationship between two or more predictors in a regression model.  <em>Perfect collinearity</em> exists when at least one predictor is a perfect linear combination of the others (e.g. two predictors have a correlation coefficient of 1).  As <em>collinearity</em> increases, these three problems arise:<ul>
<li><em>Untrustworthy bs</em> - b coefficients increase as collinearity increase; big standard errors for b coefficients mean that bs are more variable across samples, thus b is less likely to represent the population, thus predictor equations will be unstable across samples</li>
<li><em>limits size of R</em> - Having uncorrelated predictors gives you better <em>unique variance</em></li>
<li><em>importance of predictors</em> - multicollinearity makes it difficult to assess the individual importance of a predictor.  If the predictors are highly correlated then we can&rsquo;t tell which of say two variables is important</li>
</ul>
</li>
<li><em>Testing collinearity</em> - To test for collinearity, you can do the following:<ul>
<li><em>correlation matrix</em> shows relationships between variables to variables with anything above say above .8 as an indicator of really highly correlated and might be an issue, however it misses on detecting <em>multicollinearity</em> since it only looks at one variable at a time</li>
<li><em>variance inflation factor (VIF)</em> is a collinearity diagnostic that indicates whether a predictor has a strong linear relationship with another predictor(s) and is good for spotting relationships between multiple variables.  There&rsquo;s no hard and fast rules, but a 10 is a good value to start worrying or if the average <em>VIF</em> is close to 1, then <em>multicollinearity</em> might be biasing the model</li>
<li><em>tolerance statistic</em> is the reciprocal of <em>variance inflation factor (i.e. 1/VIF)</em> Any values below .1 are serious concerns</li>
</ul>
</li>
<li><em>Plotting</em> is a good way to check assumptions of regression to make sure the model generalizes beyond your sample.</li>
</ul>
</li>
<li><strong>Plotting</strong> - You can check assumptions quickly with graphs<ul>
<li>Graph the <em>standardized residuals</em> against the <em>fitted (predicted) values</em>.  <ul>
<li>If the plot looks like a random array of dots, then it&rsquo;s good.</li>
<li>If the dots seem to get more or less spread out over the graph (like a funnel shape) then is probably a violation of the assumption of <em>homogeneity of variance</em>.</li>
<li>If the dots have a pattern to them (like a curved shape) then this is probably a violation of the assumption of <em>linearity</em></li>
<li>If the dots have a pattern and are more spread out at some points on the plot than others then this probably reflects violations of both <em>homogeneity of variance</em> and <em>linearity</em></li>
</ul>
</li>
<li>Graph the histogram of the residuals<ul>
<li>If the histogram looks like a normal distribution (and the Q-Q plot looks like a diagonal line) then its good</li>
<li>If the histogram looks non-normal, then things might not be good</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="violating-linear-regression-assumptions"><a name="user-content-violating-linear-regression-assumptions" href="#violating-linear-regression-assumptions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Violating Linear Regression Assumptions</h3>
<p>If assumptions are violated, then you cannot generalize your findings beyond your sample.  You can try correcting the samples using:<br />
    -  If residuals show problems with <em>heteroscedasticity</em> or <em>non-normality</em>, you could try transforming the raw data (though might not affect the residuals)<br />
    -  If there&rsquo;s a violation of the <em>linearity</em> assumption, then you could do a logistic regression instead<br />
    -  You can also try a <em>robust regression (aka bootstrapping, robust statistics)</em>, which is an alternative to the <em>least squares regression</em> when there&rsquo;s too many outliers or influential cases</p>
<h3 id="logistic-regression-types"><a name="user-content-logistic-regression-types" href="#logistic-regression-types" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Logistic Regression - Types</h3>
<p>Logistic Regression is multiple regression, but with an outcome variable that is a categorical and predictor variables that are continuous or categorical.  There&rsquo;s two types of logistic regression:<br />
<em>  <strong>binary logistic regression</strong> is used to predict a binary response (e.g. tumor cancerous or benign).<br />
</em>  <strong>multinomial (or polychotomous) logistic regression</strong> predicts an outcome variable that has more than two categories (e.g. favorite color).<br />
*  There&rsquo;s no additional formulas between these two types of <em>logistic regression</em>; the reason is that <em>multinomial logistic regression</em> just breaks the outcome variable down into a series of comparisons between two categories.  Say we have three outcome categories (A, B, C) then the analysis will consist of a series of two comparisons (e.g. A vs B and A vs C) or (A vs C and B vs C) or (B vs A and B vs C); basically you have to select a baseline category.</p>
<h3 id="assessing-the-logistic-regression-model"><a name="user-content-assessing-the-logistic-regression-model" href="#assessing-the-logistic-regression-model" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Assessing the Logistic Regression Model</h3>
<ul>
<li>What are we measuring?  (A comparison between linear and logistic regressions)</li>
<li><strong>logit</strong> - In <em>linear/simple regression</em>, you predict the value of Y given X.  In <em>logistic regression</em>, you predict the probability of Y occuring given X.  You can&rsquo;t use <em>linear regression</em> equations on a <em>logistic regression</em> problem (i.e. outcome is a categorical instead of continuous) unless you do some data transformations (like <em>logit</em>, which logs the data)</li>
<li><strong>log-likelihood</strong> - In <em>linear/simple regression</em>, we used R^2 (the <em>Pearson correlation</em>) to check between observed values of the outcome and the values predicted by the regression model.  For <em>logistic regression</em>, we use the <em>log-likelihood</em> given by <code>insert equation</code>, which is based on summing the probabilities associated with the predicted and actual outcomes (i.e. how much unexplained information there is after the model has been fitted).  A larger <em>log-likelihood</em> means poor fitting model because there&rsquo;s more unexplained observations.  This is good for overall fit.  For partial fit, see <em>R-statistic</em>.<ul>
<li><strong>maximum-likelihood estimation (MLE)</strong> is a method to estimate the parameters of a statistical model (i.e. given a sample population, it estimates what most likely would have occured).  MLE gives you the coefficients most likely to have occurred.</li>
<li><strong>deviance (aka -2LL)</strong> is related to the <em>log-likelihood</em> and its equation is <code>deviance =-2*log-likelihood</code> and sometimes used instead of the <em>log-likelihood</em> because it has a <em>chi-square distribution</em>, which makes it easy to calculate the significance of the value.</li>
</ul>
</li>
<li>R - How the model fits the data<ul>
<li><strong>R-statistic</strong> is the partial correlation between the outcome variable and each of the predictor variables (opposed to <em>log-likelihood</em> which is for the overall correlation instead of partial); can be between -1 (meaning as the the predictor value increases, likelihood of the outcome occurring decreases) to 1 (meaning that as the predictor variable increases, so does the likelihood of the event occurring).  The equation is <code>insert equation</code>.</li>
<li><strong>Hosmer and Lemeshow&rsquo;s RL^2 measure</strong> is <code>insert equation</code> and is the proportional reduction in the absolute value of the log-likelihood measure and thus is a measure of how much the badness of fit improves as a result of the inclusion of the predictor values.  Values range from 0 (predictors are useless at predicting the outcome variable) to 1 (model predicts the outcome variable perfectly)</li>
<li><strong>Cox and Snell&rsquo;s RCS^2</strong> is <code>insert equation</code> and <strong>Nagelkerke&rsquo;s RN^2</strong> is <code>insert equation</code>, both of which are another way of getting a equivalent of R^2 in linear regression.</li>
</ul>
</li>
<li>Information Criteria - Penalize a model for having more predictors<ul>
<li><strong>Akaike Information Criterion (AIC)</strong> for logistic regression is <code>AIC = -2LL +2k</code> where <code>-2LL</code> is the <em>deviance</em> and <code>k</code> is the number of predictors</li>
<li><strong>Bayes Information Criterion (BIC)</strong> for logistic regression is <code>BIC = -2LL +2k * log(n)</code> where <code>n</code> is the number of cases</li>
</ul>
</li>
<li>How much are each predictor(s) contributing?<ul>
<li><strong>t-statistic</strong> - in linear regression, the regression coefficient <em>b</em> and their standard errors created the <em>t-statistic</em>, which tells us how much a preditor was contributing</li>
<li><strong>z-statistic (aka the Wald statistic)</strong> - in logistic regression, the <em>z-statistic</em> tells us if the <em>b</em> coefficient for that predictor is significantly different than zero.  If a coefficient <em>b</em> is much greater than zero, then that predictor is making a significant contribution to the prediction of the outcome.  <code>z = b / (SEb)</code>.  Be warned, when the z-statistic value is large, the <em>standard error</em> tends to be inflated, resulting in <em>z-statistic</em> being underestimated.  An inflated <em>standard error</em> increases the probability of rejecting a predictor as being significant when in reality it is making a significant contribution (i.e. <em>Type II error</em>)</li>
</ul>
</li>
<li>So the coefficient <em>b</em> in a <em>logistic regression</em> is an exponent instead of multiplying, how does that work out / what does it mean?<ul>
<li><strong>odds</strong> as we normally know it is the probability of something happening / something not happening (e.g. probability becoming pregnant divided by / probability of not becoming pregnant).  This isn&rsquo;t the same as the <em>logistic regression</em>&lsquo;s <em>odds ratio</em> mentioned below.</li>
<li><strong>odds ratio</strong> is the exponential of B (i.e., e^B), which is the change in odds resulting from a unit changes in the predictor.  E.g. calculate the odds of becoming pregnant when a condom is not used, calculate the odds of becoming pregnant when a condom is used, then calculate the proportionate change in odds between the two.  <ul>
<li>Formula is: <code>change in odds = odds after a unit change in the predictor / original odds</code></li>
<li>if the value is greater than 1, then it means as the predictor increases, the odds of the outcome occuring also increases</li>
<li>if the value is less than 1, then it means as the predictor increases, the odds of the outcome occuring decrease</li>
</ul>
</li>
</ul>
</li>
<li>How do we know what order to put in / take out predictors in <em>logistic regression</em>?<ul>
<li><strong>forced entry method</strong> - the default method for conducting regression; place in one block and estimate parameters for each predictor</li>
<li><strong>stepwise method</strong> - select a forward, backward, or both stepwise method (remember the issues with it though).</li>
</ul>
</li>
<li>What are Logistic Regression assumptions?<ul>
<li><strong>Linearity</strong> - In linear regression we assume the outcome had a linear relationship with the predictors.  However, logistic regression&rsquo;s outcome is categorical so our linear regression assumptions don&rsquo;t apply.  Instead, with logistic regression we check if there are any linear relationships between any continuous predictors and the <em>logit</em> of the outcome variable.</li>
<li><strong>Independence of errors</strong> - Same as linear regression where the cases of data are not related</li>
<li><strong>Multicollinearity</strong> - Same as linear regression where predictors should not be too highly correlated; can check with <em>tolerance statistic</em> and <em>VIF statistics</em>, the eigenvalues of the scaled, uncentred cross-roducts matrix, the condition indices and the variance proportions.</li>
</ul>
</li>
<li>What are situations where Logistic Regression can cause trouble?<ul>
<li>Not enough samples for specific categories (e.g. checking if people are happy, but only <em>n</em> of 1 for people that are 80-year old, Buddhist, left-handed lesbian).  To spot, create a crosstabulations and look for really high <em>standard errors</em>.  To fix, collect more data.</li>
<li><strong>complete separation</strong> is where the outcome variable can be perfectly predicted by one variable or a combination of variables.  This causes issues in that there&rsquo;s no data in the middle probabilities (where we&rsquo;re not very sure of the probability) which can cause a wide range of curves/probabilities.  E.g. tell between cats and burglars, there&rsquo;s no cats that weigh more than 15kg and no burgulars that weigh less than 30kg.  The issue is usually caused when there&rsquo;s too many variables fitted to too few cases.  To fix, collect more data or use a simpler model.</li>
</ul>
</li>
</ul>
<h3 id="comparing-two-means-aka-groups-using-t-test"><a name="user-content-comparing-two-means-aka-groups-using-t-test" href="#comparing-two-means-aka-groups-using-t-test" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Comparing two means (aka groups) using t-test</h3>
<p>We&rsquo;ve looked at relationships between variables, but sometimes we&rsquo;re interested in differences between groups of people.  This is useful in making causal inferences (e.g. two groups of people, one gets a sugar pill and other gets actual pill).  There&rsquo;s two different ways to expose people to experiments: <em>between-group</em> or <em>independent design</em> as well as exposing the same group to all experiments, just at different points in time (<em>repeated-measures design</em>).<br />
*  <strong>t-test</strong> - are used to test whether two group means are different.  There&rsquo;s two types including <em>independent-means t-test</em> and <em>dependent-means t-test</em>.  <em>t-tests</em> are basically <em>regressions</em> so it has much of the same assumptions (<em>parametric tests</em> based on a <em>normal distribution</em>).<br />
    -  <strong>independent-means t-test (aka independent-measures, independent-samples t-test)</strong> is used when there are two experimental conditions and different participants were assigned to each condition (e.g. Group 1 gets Treatment A, Group 2 gets Treatment B).  <em>independent t-tests</em> also assume that scores in different treatment conditions are <em>independent</em> (because they come from different people) and that there is <em>homogeneity of variance</em> (but this only really matters if you have unequal group sizes.  Also if this is violated, you can use <em>Welch&rsquo;s t-test</em> to adjust your data, which you should always do)<br />
    -  <strong>dependent-means t-test (aka matched-pairs, pair-samples t-test, paired t-test)</strong> - is used when there are two experimental conditions and the same participants took part in both conditions of the experiment (e.g. Group 1 gets Treatment A, Group 2 gets Treatment B, then swap with Group 1 gets Treatment B, Group 2 gets Treatment A).  The sampling distribution of the differences between scores should be a <em>normal distribution</em> (not the scores themselves)<br />
    - Calculations for <em>t-tests</em> can be viewed as if the <em>t-test were a linear regression (GLM)</em>.  The <em>independent t-test</em> can be seen as comparing the model as effect against the error.  The <em>dependent t-test</em> can be seen as   Note: Don&rsquo;t really worry about the below, <em>R</em> will do the calculations:<br />
        *  <strong>Generalized Linear Model (GLM), (i.e. t-test as a linear regression)</strong> the <em>t-test</em> can be thought of as a form of <em>linear regression</em>.  It&rsquo;ll allow you to test differences between two means.<br />
        -  E.g. say you have two groups (one looks at picture of spider versus other that looks at a real spider and you measure their anxiety as heartrate).  The <em>t-test</em> as a <em>GLM</em> would setup each group (picture vs real spider) with the equation <code>outcome = (model) + error</code>.  We <em>dummy code</em> the group variable (say Group 1 has value of 0 and Group 2 has value of 1).  We calculate the anxiety across both groups and then test whether the difference between group means is equal to 0.  The <em>t-statistic</em> tests if the difference between group means is significantly different than zero.<br />
        *  <strong>Independent t-test (i.e. t-test as comparing the model or effect against the error)</strong>  This means that when different groups participate in different conditions, pairs of scores will differ not just because of the experiment&rsquo;s manipulation, but also because of other sources of variance (e.g. IQ).  Therefore, we make comparisons on a &lsquo;per condition&rsquo; basis&rsquo;.  By looking at the &lsquo;per condition basis&rsquo;, we assess whether the difference between two sample means is statistically meaningful or by chance (through numerous sampling and looking at the sampling means distribution).<br />
        *  <strong>Dependent t-test</strong> Since we put the same group through multiple experiments, we need to see the score in condition A compared to condition B and add up the differences (could be large or small) for all participants.  We divide by the number of participants in the group and get the average difference (on average, how much each person&rsquo;s score changed in condition A to condition B).  We then compare (divide) this by the standard error (which represents if we just randomly sampled from the population and not done any experiments).  This gives us the <em>test statistic</em> that represents the model/error. <br />
<strong>t-statistic (aka test statistic)</strong> - <em>t-tests</em> produce the <em>t-statistic</em>, which tells us how extreme a statistical estimate is.  If the experiment had any kind of effect, we expect the systematic variation to be much greater than the unsystematic variation (i.e. if <em>t</em> is much greater than 1, there&rsquo;s an effect; if <em>t</em> is less than 1, there&rsquo;s no effect.  If <em>t</em> exceeds the critical value for an effect, we&rsquo;re confident that this reflects an effect of our independent variable)<br />
    - <strong>effect-size and t-tests</strong> - even though a <em>t-statistic</em> might not be statistically significant, it doesn&rsquo;t mean that our effect is unimportant.  To check if an <em>effect-size</em> is substantive, we use the following equation: ``<br />
    - Reporting <em>t-tests</em> should involve stating the finding to which the test relates, report the <em>test statistic</em>, <em>degrees of freedom</em>, an estimate of the <em>effect-size</em>, and the <em>probability</em> of that test statistic.  E.g. On average, participants experienced greater anxiety from real spiders (M = 47.00, SE = 3.18), than from pictures of spiders (M=40.00, SE = 2.68).  This difference was not significant t(21.39) = -1.68, p&gt;.05; however, it did represent a medium-sized effect r=.34</p>
<h3 id="comparing-several-means-with-anova-analysis-of-variance-glm-1"><a name="user-content-comparing-several-means-with-anova-analysis-of-variance-glm-1" href="#comparing-several-means-with-anova-analysis-of-variance-glm-1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Comparing Several Means with ANOVA (Analysis of Variance, GLM 1)</h3>
<p>If we want to compare more than two conditions, we use <em>ANOVA</em>.  <em>t-tests</em> checked whether two samples have the same mean while <em>ANOVA</em> checks if three or more groups have the same means.  <em>ANOVA</em> is an <em>omnibus</em> test, which means it tests for an overall effect between all groups and does not say what group has a different mean.<br />
    - <strong>familywise (aka experimentwise error rate)</strong> is the error rate across statistical tests conducted on the same experimental data.  For example, we use <em>ANOVA</em> instead of using multiple <em>t-tests</em> on each pair of groups because the probability of <em>Type I</em> errors would quickly stack (e.g. say .05 level of significance with 3 pairs would be .95 * .95 * .95 = .857 probability of no <em>Type I error</em>).  The more groups the more chance of an error.<br />
    - <strong>F-statistic (aka F-ratio)</strong> is the ratio of the model to its error (much like the <em>t-statistic</em>).  Say we have Groups A, B, C.  The <em>F-ratio</em> tells us if the means of these three groups (as a whole) are different.  It can&rsquo;t tell what groups are different (e.g. if groups A and B are the same and C is different, if groups A, B, C are all different).  <em>F-ratio</em> says that the experimental manipulation has some effect, but doesn&rsquo;t say what causes the effect.  The <em>F-ratio</em> can be used to fit a multiple regression model and test the differences between the means (again, much like the <em>t-statistic</em> with a linear regression)<br />
    - When creating <em>dummy variables</em> for <em>ANOVA</em> groups (e.g. Group A, B, C) where we have one less dummy variable than the number of groups in the experiment.  We choose a <em>control group (aka baseline group)</em> that acts as a baseline for other categories.  This baseline group is usually the one with no experiments (e.g. baseline is no viagra and others are low dose and high dose viagra).  When group sizes are unequal, the baseline group should have a large number of samples.<br />
<em> <strong>Assessing variation (deviance)</strong><br />
At every stage of the <em>ANOVA</em> we&rsquo;re assessing <em>variation</em> (or <em>deviance</em>) from a particular model using the formula <code>deviation = change in (observed - model)^2</code>.  We calculate the fit of the most basic model, then the fit of the best model; if the model is any good then it should fit the data significantly better than the basic model.<br />
    - <strong>Total Sum of Squares (aka TSS, SST)</strong> gives us the total amount of variation.  We calculate the difference between each observed data point and the grand mean.  We then square these differences and add them together to get us the <em>total sum of squares</em>.<br />
        + For <em>TSS</em>, the <em>degrees of freedom</em> is one less than the total sample size (N-1); the mean is the constant being held.  The equation is <code>N-1</code>  E.g. we have 15 participants, the degrees of freedom is 14.<br />
    - <strong>grand variance</strong> is the variance between all scores, regardless of the experimental condition, and can be used to calculate the <em>total sum of squares</em> with the equation <code>&lt;insert equation&gt;</code><br />
    - <strong>Model Sum of Squares (SSm)</strong> tells us how much of the total variation can be explained by the fact that different data points come from different groups.  We calculate the difference between the mean of each group and the grand mean, square the differences, multiply each result by the number of participants within that group, then add the values for each group together.<br />
        + For <em>SSm</em>, the <em>degrees of freedom</em> is one less than the number of parameters estimated.  The equation is: <code>k-1</code>  E.g. with 3 groups of participants, we have 2 degrees of freedom.<br />
    - <strong>Residual Sum of Squares (SSr)</strong> tells us how much of the variation cannot be explained by the model (e.g. individual differences in weight, testosterone, etc in particpants).  <em>SSr</em> can be seen by looking at the difference between the score obtained by a person and the mean of the group that the person belongs.<br />
        + For <em>SSr</em>, the <em>degrees of freedom</em> are the total degrees of freedom (i.e. the total sample size <code>N</code>) minus the degrees of freedom for the model (i.e. the number of groups <code>k</code>).  The equation is: <code>N-k</code>.  E.g. with 15 participants and 3 groups, we have (14 - 2 = 12) degrees of freedom. <br />
    - <strong>Mean Squares (MS)</strong> eliminates the bias of the number of scores (because <em>SSm</em> and <em>SSr</em> tells us the total, not the average).  <em>MS</em> gives us the the <em>sum of squares</em> divided by the <em>degrees of freedom</em>.<br />
        + <em>MSm</em> is the average amount of variation explained by the model (the systematic variation)<br />
        + <em>MSr</em> is the average amount of variation explained by extraneous variables (the unsystematic variation)<br />
        + <em>F-ratio</em> is the measure of the ratio of the variation explained by the model and the variation explained by unsystematic factors (i.e. how good the model is against how much error there is).  The equation is: <code>(_MSm_)/(_MSr_)</code><br />
    - Assumptions of <em>ANOVA</em> include:<br />
        + <em>Homogeneity of variance</em> - the variances of the groups are equal.  You can check this using <em>Levene&rsquo;s test</em>, which is an <em>ANOVA test</em> done on the absolute differences between the observed data and the mean or median.  If <em>Levene&rsquo;s test</em> is significant (i.e. p-value is less than .05) then the variances are significantly different and we shouldn&rsquo;t use <em>ANOVA</em>.<br />
        + Note that <em>ANOVA</em> is a <em>robust test</em>, which means it doesn&rsquo;t matter if we break some assumptions (the <em>F-ratio is still accurate</em>).  When group sizes are equal, then <em>F-ratio</em> is quite robust.  However, when group sizes are not equal, the accuracy of <em>F-ratio</em> is affected by <em>skew</em>.<br />
        + If <em>homogeneity of variance</em> has been violated, you can try different data transformations or you can try a different version of the <em>F-ratio</em>, like <em>Welch&rsquo;s F</em>.<br />
        + If there&rsquo;s distributional problems, there are other methods like <em>bootstrapping</em> or <em>trimmed means</em> and <em>M-estimators</em> that can correct for it.</em>  <strong>Planned contrasts</strong> tells us which groups differ in an <em>ANOVA</em>.  This is important because <em>F-ratio</em> tells if there&rsquo;s an effect, but not what group causes it.  <em>Planned contrasts</em> are a way of comparing different groups without causing <em>familywise error rate</em>.  We can do this using two methods:<br />
    1.  <strong>planned comparisons (aka planned constrasts)</strong> - break down the <em>variance</em> accounted for by the model into component parts.  This is done when you have a specific hypotheses to test.<br />
    2.  <strong>post hoc tests (aka post hoc comparisons)</strong> - Compare every group (like you&rsquo;re doing multiple <em>t-tests</em>) but using a stricter acceptance criterion so that the familywise error rate doesn&rsquo;t rise above the acceptable .05.  This is done when you have no specific hypothesis to test.</p>
<p><remember to continue here for more ANOVA notes></p>
<h3 id="comparing-categorical-variables"><a name="user-content-comparing-categorical-variables" href="#comparing-categorical-variables" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Comparing Categorical Variables</h3>
<p>For continuous variables we measure using the means, but this is useless for categorical variables (since we&rsquo;d assign numbers to categories and it would just depend on how many categories there were).  Instead, for categorical variables, we count the <em>frequency</em> of the category to get a <em>contingency table</em>, which is a tabulation of the frequencies.  We use different algorithms depending on how many categorical variables there are (2 or more than 2).<br />
<em>  <strong>Pearson&rsquo;s chi-square statistic (aka chi-square test)</strong> is used to compare the relationship between two categorical variables.  This is given by the equation <code></code>, which is a variation on <code>deviation = change in (observed -model)^2</code>.  Note that this is only an approximation (which works really well for large samples), but if the sample size is too small, use <em>Fisher&rsquo;s exact test</em>, <em>likelihood ratio</em>, or <em>Yate&rsquo;s continuity correction</em> to avoid making <em>Type I errors</em>.<br />
    -  <strong>Fisher&rsquo;s exact test</strong> is a way to compute the exact probability of the <em>chi-square statistic</em>, useful for when the sample sizes are too small.  Usually this is used on 2 * 2 contingency tables (two categorical variables each with two categorical options) and small sample size, but can be used on larger at the cost of really intensive calculations<br />
    -  <strong>likelihood ratio statistic</strong> is an alternative to the <em>Pearson&rsquo;s chi-square</em> and is based on the <em>maximum-likelihood theory</em>.  The idea is that you collect some data and create a model for which the probability of obtaining the observed set of data is maximized, then you compare this model to the probability of obtaining those data under the null hypothesis.  You then compare observed frequencies with those predicted by the model.  This is roughly the same as <em>Pearson&rsquo;s chi-square</em>, but preferred when samples are small.  The equation is: <code></code><br />
    -  <strong>Yate&rsquo;s continuity correction</strong> is used specifically for 2 * 2 contingency tables because for these cases <em>Pearson&rsquo;s chi-square</em> tends to make <em>Type I</em> errors.  Be careful though, this sometimes overcorrects and produces a <em>chi-square</em> value that is too small .  The equation is: <code></code></em>  Assumptions of <em>chi-square test</em> are:<br />
    -  Independence of data - this means that each person, item, entity contributes to only one cell of the contingency table; you can&rsquo;t use this on a <em>repeated measures design</em> (e.g. train cats with food to dance, then trained the same cats with affection to see if they would dance)<br />
    -  Expected fequencies should be greater than 5; although in larger contingency tables, it&rsquo;s okay to have up to 20% of expected frequencies below 5, the result is loss of statistical power (which means the test might fail to detect a genuine effect)</p></article></body></html>